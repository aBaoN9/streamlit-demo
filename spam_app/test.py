import re
import numpy as np
import pandas as pd
import streamlit as st

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score
)
from sklearn.ensemble import VotingClassifier
from sklearn.preprocessing import LabelEncoder

st.set_page_config(page_title="SMS Spam Classifier", page_icon="üì©", layout="wide")
st.title("üì© SMS Spam Classifier ‚Äî Naive Bayes vs Decision Tree (Voting & Stacking)")

# =========================
# Helpers
# =========================
@st.cache_data(show_spinner=False)
def load_csv(file) -> pd.DataFrame:
    df = pd.read_csv(file)
    # Try to normalize common schemas
    cols = [c.lower().strip() for c in df.columns]
    df.columns = cols
    # Try to map typical column names
    if "label" not in df.columns:
        # Try 'category', 'target', etc.
        for cand in ["category", "target", "class"]:
            if cand in df.columns:
                df["label"] = df[cand]
                break
    if "text" not in df.columns:
        for cand in ["message", "sms", "content", "body"]:
            if cand in df.columns:
                df["text"] = df[cand]
                break
    # Keep only needed cols
    if not {"label", "text"}.issubset(df.columns):
        raise ValueError("File CSV c·∫ßn c√≥ 2 c·ªôt: 'label' v√† 'text' (ho·∫∑c t√™n t∆∞∆°ng ƒë∆∞∆°ng).")
    # Drop NA + strip
    df = df[["label", "text"]].dropna()
    df["label"] = df["label"].astype(str).str.lower().str.strip()
    df["text"] = df["text"].astype(str).str.strip()
    # Normalize label variants
    df["label"] = df["label"].replace(
        {"spam": "spam", "ham": "ham", "1":"spam", "0":"ham", "spam msg":"spam", "normal":"ham"}
    )
    return df

def make_vectorizer(kind: str):
    if kind == "Word (1-2gram)":
        return TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.95)
    elif kind == "Char (3-5gram)":
        return TfidfVectorizer(analyzer="char", ngram_range=(3,5), min_df=2, max_df=0.95)
    else:
        return TfidfVectorizer(ngram_range=(1,1), min_df=2, max_df=0.95)

def build_model(model_name: str, vec_kind: str):
    vec = make_vectorizer(vec_kind)

    if model_name == "Naive Bayes":
        clf = MultinomialNB()
        pipe = Pipeline([("vec", vec), ("clf", clf)])
        return pipe

    if model_name == "Decision Tree":
        clf = DecisionTreeClassifier(
            criterion="gini", max_depth=None, random_state=42, min_samples_leaf=1
        )
        pipe = Pipeline([("vec", vec), ("clf", clf)])
        return pipe

    if model_name == "Voting (NB + DT, soft)":
        nb = ("nb", Pipeline([("vec", vec), ("clf", MultinomialNB())]))
        dt = ("dt", Pipeline([("vec", vec), ("clf", DecisionTreeClassifier(random_state=42))]))
        # Soft voting needs predict_proba ‚Äî c·∫£ NB v√† DT ƒë·ªÅu h·ªó tr·ª£
        clf = VotingClassifier(estimators=[nb, dt], voting="soft", n_jobs=None, flatten_transform=True)
        return clf

    if model_name == "Stacking (NB+DT -> LR)":
        # Stacking v·ªõi vectorizer chia s·∫ª: ta l√†m "2 pipeline ri√™ng" -> l·∫•y x√°c su·∫•t, gh√©p c·ªôt
        # ƒê·ªÉ ƒë∆°n gi·∫£n trong Streamlit: ta hu·∫•n luy·ªán 2 base model ri√™ng v√† meta LR tr√™n output probs.
        # Ta b·ªçc b·∫±ng m·ªôt class nh·ªè ƒë·ªÉ c√≥ fit/predict nh·∫•t qu√°n.
        class StackingWrapper:
            def __init__(self, vec_kind):
                self.vec_kind = vec_kind
                self.nb = Pipeline([("vec", make_vectorizer(vec_kind)), ("clf", MultinomialNB())])
                self.dt = Pipeline([("vec", make_vectorizer(vec_kind)), ("clf", DecisionTreeClassifier(random_state=42))])
                self.meta = LogisticRegression(max_iter=200)

            def fit(self, X, y):
                self.lb = LabelEncoder().fit(y)
                y_enc = self.lb.transform(y)
                self.nb.fit(X, y_enc)
                self.dt.fit(X, y_enc)
                Z = self._stack_features(X)  # probs concat
                self.meta.fit(Z, y_enc)
                return self

            def _stack_features(self, X):
                p1 = self.nb.predict_proba(X)
                p2 = self.dt.predict_proba(X)
                return np.hstack([p1, p2])

            def predict(self, X):
                Z = self._stack_features(X)
                y_hat = self.meta.predict(Z)
                return self.lb.inverse_transform(y_hat)

            def predict_proba(self, X):
                Z = self._stack_features(X)
                return self.meta.predict_proba(Z)

        return StackingWrapper(vec_kind)

    raise ValueError("Unknown model.")

def evaluate(y_true, y_pred, y_proba=None, pos_label="spam"):
    acc = accuracy_score(y_true, y_pred)
    pre = precision_score(y_true, y_pred, pos_label=pos_label, zero_division=0)
    rec = recall_score(y_true, y_pred, pos_label=pos_label, zero_division=0)
    f1  = f1_score(y_true, y_pred, pos_label=pos_label, zero_division=0)
    cm  = confusion_matrix(y_true, y_pred, labels=[pos_label, "ham"])
    roc = None
    if y_proba is not None and len(np.unique(y_true)) == 2:
        # map labels to {1,0} w.r.t pos_label
        y_bin = (np.array(y_true) == pos_label).astype(int)
        # Find column index of pos_label if proba is aligned with classes
        if isinstance(y_proba, pd.DataFrame):
            p_spam = y_proba[pos_label].values
        else:
            # assume column order [ham, spam] or [0,1]? try to infer:
            # safer: if y_proba has 2 columns, pick the second as "spam" (common for LabelEncoder=ham(0),spam(1))
            p_spam = y_proba[:, -1]
        try:
            roc = roc_auc_score(y_bin, p_spam)
        except Exception:
            roc = None
    return acc, pre, rec, f1, cm, roc


# =========================
# Sidebar controls
# =========================
st.sidebar.header("‚öôÔ∏è C·∫•u h√¨nh")
model_name = st.sidebar.selectbox(
    "Ch·ªçn m√¥ h√¨nh", 
    ["Naive Bayes", "Decision Tree", "Voting (NB + DT, soft)", "Stacking (NB+DT -> LR)"],
    index=0
)
vec_kind = st.sidebar.selectbox(
    "Ki·ªÉu vector h√≥a TF-IDF",
    ["Word (1-2gram)", "Char (3-5gram)", "Word (1-gram)"],
    index=0
)
test_size = st.sidebar.slider("T·ªâ l·ªá test", 0.1, 0.4, 0.2, 0.05)
random_state = st.sidebar.number_input("random_state", min_value=0, value=42, step=1)
pos_label = "spam"

st.sidebar.markdown("---")
st.sidebar.caption("üí° D·ªØ li·ªáu CSV c·∫ßn c√≥ c·ªôt `label` (spam/ham) v√† `text`.")

# =========================
# Data input
# =========================
tab1, tab2 = st.tabs(["üìÇ D·ªØ li·ªáu", "üß™ D·ª± ƒëo√°n nhanh"])

with tab1:
    uploaded = st.file_uploader("T·∫£i file CSV c·ªßa b·∫°n (label, text)", type=["csv"])
    use_sample = st.checkbox("D√πng file m·∫´u 20 d√≤ng (song ng·ªØ) n·∫øu ch∆∞a c√≥ d·ªØ li·ªáu", value=False)

    if uploaded is None and not use_sample:
        st.info("H√£y t·∫£i file CSV ho·∫∑c ch·ªçn d√πng file m·∫´u.")
    else:
        if use_sample:
            df = pd.read_csv("sample_sms_spam.csv") if False else None  # placeholder: not used
            # Thay v√¨ ƒë·ªçc file c·ª•c b·ªô, ta generate nh·ªè trong code cho demo:
            data = [
                ("spam","Congratulations! You have won a $1000 gift card. Click here to claim now."),
                ("ham","Hey, are we still on for lunch at 12?"),
                ("spam","URGENT: Your account will be suspended. Verify your details at http://bit.ly/xyz"),
                ("ham","I'll be late to the meeting by 10 minutes."),
                ("spam","Claim your FREE vacation now!!! Reply YES to win."),
                ("ham","Please review the attached report and send me your feedback."),
                ("spam","You have been selected for a limited-time offer. Apply now!"),
                ("ham","Thanks for the birthday wishes!"),
                ("spam","Final notice: Payment required to avoid penalty. Pay at secure link."),
                ("ham","Can you pick up milk on your way home?"),
                ("spam","Ch√∫c m·ª´ng! B·∫°n tr√∫ng th∆∞·ªüng iPhone 15. B·∫•m v√†o link ƒë·ªÉ nh·∫≠n qu√†."),
                ("ham","T·ªëi nay 7h l·ªõp m√¨nh h·ªçc Zoom nh√©."),
                ("spam","C·∫£nh b√°o: T√†i kho·∫£n c·ªßa b·∫°n s·∫Ω b·ªã kh√≥a trong 24h. X√°c minh ngay."),
                ("ham","Mai h·ªçp nh√≥m ·ªü th∆∞ vi·ªán, nh·ªõ mang laptop."),
                ("spam","Nh·∫≠n qu√† mi·ªÖn ph√≠ ch·ªâ h√¥m nay! Tr·∫£ l·ªùi YES ƒë·ªÉ nh·∫≠n."),
                ("ham","M√¨nh ƒë√£ chuy·ªÉn kho·∫£n ti·ªÅn nh√† r·ªìi nha."),
                ("spam","Khuy·∫øn m√£i si√™u s·ªëc! Mua 1 t·∫∑ng 1. Click ngay!"),
                ("ham","C·∫£m ∆°n b·∫°n ƒë√£ h·ªó tr·ª£ m√¨nh h√¥m qua."),
                ("spam","Th√¥ng b√°o cu·ªëi: N·ªôp ph√≠ ngay ƒë·ªÉ tr√°nh ph·∫°t. Xem link b·∫£o m·∫≠t."),
                ("ham","B·∫°n g·ª≠i m√¨nh file b√†i t·∫≠p v·ªõi nh√©."),
            ]
            df = pd.DataFrame(data, columns=["label","text"])
        else:
            df = load_csv(uploaded)

        st.success(f"ƒê√£ n·∫°p {len(df)} d√≤ng. T·ªâ l·ªá spam: {(df['label']=='spam').mean()*100:.2f}%")
        st.dataframe(df.head(10), use_container_width=True)

        # Split
        X_train, X_test, y_train, y_test = train_test_split(
            df["text"].values, df["label"].values,
            test_size=test_size, random_state=random_state, stratify=df["label"].values
        )

        # Build + fit
        model = build_model(model_name, vec_kind)
        with st.spinner("ƒêang hu·∫•n luy·ªán..."):
            model.fit(X_train, y_train)

        # Predict
        if hasattr(model, "predict_proba"):
            y_proba = model.predict_proba(X_test)
        else:
            y_proba = None
        y_pred = model.predict(X_test)

        # Evaluate
        acc, pre, rec, f1, cm, roc = evaluate(y_test, y_pred, y_proba=y_proba, pos_label=pos_label)

        c1, c2, c3, c4, c5 = st.columns(5)
        c1.metric("Accuracy", f"{acc:.3f}")
        c2.metric("Precision (spam)", f"{pre:.3f}")
        c3.metric("Recall (spam)", f"{rec:.3f}")
        c4.metric("F1 (spam)", f"{f1:.3f}")
        c5.metric("ROC-AUC", f"{roc:.3f}" if roc is not None else "‚Äî")

        st.markdown("#### Confusion Matrix (labels: [spam, ham])")
        cm_df = pd.DataFrame(cm, index=["spam_true","ham_true"], columns=["spam_pred","ham_pred"])
        st.dataframe(cm_df, use_container_width=True)

        st.markdown("#### Classification Report")
        st.text(classification_report(y_test, y_pred, zero_division=0))

with tab2:
    st.write("Nh·∫≠p m·ªôt ho·∫∑c nhi·ªÅu tin nh·∫Øn, m·ªói d√≤ng l√† m·ªôt tin:")
    user_text = st.text_area("Tin nh·∫Øn", height=160, placeholder="V√≠ d·ª•:\nDear valued customer, verify your account at ...\nT·ªëi nay h·ªçp nh√≥m l√∫c 7h nh√©.")
    if "last_trained_model" not in st.session_state:
        st.session_state["last_trained_model"] = None
        st.session_state["model_name"] = None

    predict_btn = st.button("Ph√¢n lo·∫°i")
    if predict_btn:
        if user_text.strip() == "":
            st.warning("Nh·∫≠p √≠t nh·∫•t 1 d√≤ng tin nh·∫Øn.")
        else:
            # For quick demo, we re-train a tiny model on-the-fly using demo data
            # In a real session, you would keep the trained model from Tab 1 (shared state),
            # but Streamlit may re-run script; easiest is to train on minimal embedded data:
            data_demo = [
                ("spam","Congratulations! You have won a $1000 gift card. Click here to claim now."),
                ("ham","Hey, are we still on for lunch at 12?"),
                ("spam","URGENT: Your account will be suspended. Verify your details at http://bit.ly/xyz"),
                ("ham","I'll be late to the meeting by 10 minutes."),
                ("spam","Ch√∫c m·ª´ng! B·∫°n tr√∫ng th∆∞·ªüng iPhone 15. B·∫•m v√†o link ƒë·ªÉ nh·∫≠n qu√†."),
                ("ham","Mai h·ªçp nh√≥m ·ªü th∆∞ vi·ªán, nh·ªõ mang laptop.")
            ]
            df_demo = pd.DataFrame(data_demo, columns=["label","text"])
            small_model = build_model(model_name, vec_kind)
            small_model.fit(df_demo["text"], df_demo["label"])

            lines = [ln.strip() for ln in user_text.split("\n") if ln.strip()]
            preds = small_model.predict(lines)
            probs = None
            if hasattr(small_model, "predict_proba"):
                proba = small_model.predict_proba(lines)
                # heuristic: take spam prob as last column
                probs = proba[:, -1]

            res = pd.DataFrame({"text": lines, "pred": preds})
            if probs is not None:
                res["P(spam)"] = probs.round(3)

            st.success("K·∫øt qu·∫£ d·ª± ƒëo√°n:")
            st.dataframe(res, use_container_width=True)
            st.caption("G·ª£i √Ω: P(spam) cao ‚Üí kh·∫£ nƒÉng l√† tin nh·∫Øn r√°c/phishing.")

st.markdown("---")
st.caption("üë©‚Äçüî¨ M·∫πo: D√πng **Voting** ho·∫∑c **Stacking** ƒë·ªÉ tƒÉng ƒë·ªô ·ªïn ƒë·ªãnh. Th·ª≠ thay ƒë·ªïi ki·ªÉu vector TF-IDF (Word vs Char) ƒë·ªÉ ph√π h·ª£p d·ªØ li·ªáu Vi·ªát/Anh.")
